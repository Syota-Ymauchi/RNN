{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Translation"
      ],
      "metadata": {
        "id": "MvI6yJTCHjRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker # データセットを使用可能にする"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgtri8LnPO9A",
        "outputId": "1042bb2a-03c8-48b3-89e1-928aad915588"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ynNhFnZ5O5wH",
        "outputId": "02598fe8-a493-4621-a24b-71db6344b8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.16 in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16) (2.32.3)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext==0.16) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext==0.16) (2.2.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16) (12.6.68)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext==0.16) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# バージョン0.16ならうまくいったので\n",
        "! pip install torchtext==0.16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd5WaprzXspS",
        "outputId": "0415d173-5e49-48d1-97a7-c0280fc8a410"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ準備"
      ],
      "metadata": {
        "id": "pKUTnVOKPHZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.datasets import Multi30k # 機械翻訳用のデータセット\n",
        "from torchtext.data.utils import get_tokenizer # token 作成\n",
        "from torchtext.vocab import build_vocab_from_iterator # 辞書作成"
      ],
      "metadata": {
        "id": "o0nq22lTPbYa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データのロード\n",
        "data = Multi30k(split='train', language_pair=('de', 'en')) # dataを返すジェネレーター\n",
        "data = list(data)"
      ],
      "metadata": {
        "id": "TgaquLiUPltO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの分割\n",
        "train_data, remaining = train_test_split(data, train_size=0.1, random_state=0)\n",
        "_, val_data = train_test_split(remaining, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "WfuOGfdIP9-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3159NXvfSlZB",
        "outputId": "bfd74ef7-8d06-4cd1-fa6f-7a3d03087afa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2900 5221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "# tokenizerは一つのオブジェクトにするのが良い\n",
        "token_transform = {}\n",
        "\n",
        "# enやdeもよく使う文字列となるので変数にする\n",
        "# 大文字で定義する変数 -> コンスタンツ　: 定義した後に変更されない(pythonでは出来ないが読み手に伝えることは出来る)\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "# tokenizerのオブジェクト化\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    token_transform[ln] = get_tokenizer('spacy', language=ln)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y7OBYK-TZ6F",
        "outputId": "989c011f-3db9-4860-dadd-1f98ab9a833f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE]('ich lerne Deutsch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpekfFfYlIO",
        "outputId": "2993fa30-bade-4c61-f338-7475fc123bd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ich', 'lerne', 'Deutsch']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[TGT_LANGUAGE]('I have a pen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BRZmGO4YAXm",
        "outputId": "a3aa47ba-73d7-4756-9d45-06852c683322"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'have', 'a', 'pen']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 辞書作成"
      ],
      "metadata": {
        "id": "9rgbAGvuMY2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def yield_tokens(data_iter, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE : 1}\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "specials=['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "# これも一つのオブジェクトにまとめる\n",
        "vocab_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(data, ln), specials=specials)\n",
        "    # 今回は全ての単語で辞書を作っているのでunknownはない想定\n",
        "    vocab_transform[ln].set_default_index(vocab_transform[ln]['<unk>'])\n"
      ],
      "metadata": {
        "id": "SYFi17Q1Yugs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform['en']['cat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8rKW7TNKDWJ",
        "outputId": "2032d579-3ec6-42d2-9b45-4b54f60d5d59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "813"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### tokenizerの定義と辞書作成を一つに\n",
        "\n",
        "# def yield_tokens(data_iter, language):\n",
        "#     language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE : 1}\n",
        "#     for data_sample in data_iter:\n",
        "#         yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# token_transform = {}\n",
        "# vocab_transform = {}\n",
        "# SRC_LANGUAGE = 'de'\n",
        "# TGT_LANGUAGE = 'en'\n",
        "# specials=['<unk>', '<pad>', '<bos>', 'eos']\n",
        "\n",
        "\n",
        "# # tokenizer、辞書のオブジェクト化\n",
        "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "#     token_transform[ln] = get_tokenizer('spacy', language=ln)\n",
        "#     vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(data, ln), specials=specials)\n",
        "#     vocab_transform[ln].set_default_index(vocab_transform[ln]['<unk>'])\n"
      ],
      "metadata": {
        "id": "dJHUCyQaKtu1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 符号化の課程"
      ],
      "metadata": {
        "id": "UTXzx4zJN_zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. token化\n",
        "print(token_transform[TGT_LANGUAGE](train_data[0][1]))\n",
        "# 2. 符号化\n",
        "print([vocab_transform[TGT_LANGUAGE][token] for token in token_transform[TGT_LANGUAGE](train_data[0][1])])\n",
        "# 3. tensor化\n",
        "print(torch.tensor([vocab_transform[TGT_LANGUAGE][token] for token in token_transform[TGT_LANGUAGE](train_data[0][1])]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2n6ug6wQMAe",
        "outputId": "9cf71c90-b621-479d-efbd-8dea1f9e8514"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Two', 'people', 'are', 'walking', 'on', 'a', 'striped', 'path', '.']\n",
            "[19, 22, 17, 42, 9, 4, 198, 297, 5]\n",
            "tensor([ 19,  22,  17,  42,   9,   4, 198, 297,   5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocess(data_iter):\n",
        "    data = []\n",
        "    for (src, tgt) in data_iter:\n",
        "        src_tensor = torch.tensor([vocab_transform[SRC_LANGUAGE][token] for token in token_transform[SRC_LANGUAGE](src)])\n",
        "        tgt_tensor = torch.tensor([vocab_transform[TGT_LANGUAGE][token] for token in token_transform[TGT_LANGUAGE](tgt)])\n",
        "        data.append((src_tensor, tgt_tensor))\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "x6HhqI11Q31Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_tensor = data_preprocess(train_data)\n",
        "val_data_tensor = data_preprocess(val_data)"
      ],
      "metadata": {
        "id": "s8t0WFD3Sj9N"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_tensor[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8besDUHnSxV5",
        "outputId": "aa6037e3-97e3-46fa-d489-29db9fa1d12f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 21,  42,  77,  11,   6, 259, 237,   4]),\n",
              "  tensor([ 19,  22,  17,  42,   9,   4, 198, 297,   5])),\n",
              " (tensor([   5,   12,   70,   11,   13, 3256,   15,  428,   10,   26,  189,    4]),\n",
              "  tensor([   6,   12,    9,    4, 1347, 1226,  173,    4,  267,  328,    5])),\n",
              " (tensor([    5,    12,    10,  2012,    70, 13529]),\n",
              "  tensor([   6,   12,  581, 1066,   14,   27,  570,  359,    9,    5]))]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### padding、DataLoader作成"
      ],
      "metadata": {
        "id": "PMD4nUkyTPBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch = []\n",
        "    tgt_batch = []\n",
        "    for src, tgt in batch:\n",
        "\n",
        "        src_batch.append(torch.cat([torch.tensor([vocab_transform[SRC_LANGUAGE][\"<bos>\"]]),\n",
        "                                    src,\n",
        "                                    torch.tensor([vocab_transform[SRC_LANGUAGE][\"<eos>\"]])], dim=0))\n",
        "\n",
        "        tgt_batch.append(torch.cat([torch.tensor([vocab_transform[TGT_LANGUAGE][\"<bos>\"]]),\n",
        "                                    tgt,\n",
        "                                    torch.tensor([vocab_transform[TGT_LANGUAGE][\"<eos>\"]])], dim=0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=vocab_transform[SRC_LANGUAGE]['<pad>']) # vocab_transform['de']['<pad>'] : 1\n",
        "\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=vocab_transform[TGT_LANGUAGE]['<pad>']) # vocab_transform['en']['<pad>'] : 1\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "train_loader = DataLoader(train_data_tensor, batch_size=16, collate_fn=collate_fn, shuffle=True)\n",
        "val_loader = DataLoader(val_data_tensor, batch_size=16, collate_fn=collate_fn, shuffle=False)\n"
      ],
      "metadata": {
        "id": "B10h8R7uUOvu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src, tgt = next(iter(train_loader))\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSnjLKJSVNJY",
        "outputId": "b0084e52-cb98-4a7e-a861-ccb7321c55d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 20])\n",
            "torch.Size([16, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([vocab_transform[SRC_LANGUAGE][\"<eos>\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkxSE6wwVdsR",
        "outputId": "965b9f6f-2e3b-4dbc-f655-a6916c71393f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([vocab_transform[TGT_LANGUAGE][\"<bos>\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEBZ_sEKV-0_",
        "outputId": "0a018634-4837-4938-fcc1-647cba623d2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデル構築"
      ],
      "metadata": {
        "id": "OAMS6snYRANh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, embedding_matrix=None, num_layers=1, rnn_type='LSTM', bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.num_directional = 2 if bidirectional else 1\n",
        "\n",
        "        # emdedding layer\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        input_size = embedding_dim\n",
        "\n",
        "        # rnn typeを選択する処理\n",
        "        if rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        else:\n",
        "            raise ValueError('Unsupported RNN type. Choose from [\"LSTM\", \"RNN\", \"GRU\"]')\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*self.num_directional, output_size)"
      ],
      "metadata": {
        "id": "8CN-onbJckxw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoderとdecoder作成\n",
        "class Encoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers):\n",
        "        super().__init__(vocab_size, embedding_dim, hidden_size, hidden_size, num_layers=num_layers, rnn_type='LSTM', bidirectional=False)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        output_seq, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "EpHWU2XMAW-i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "\n",
        "class Decoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1):\n",
        "\n",
        "        \"\"\"\n",
        "        vocab_size : ターゲット(今回では英語のvocab_size)\n",
        "        embedding_dim : vocab_sizeを何次元に圧縮するか\n",
        "        hidden_size : 隠れ層の次元\n",
        "        num_layers : Deep RNN に対応 多くて3くらい デフォルトで1\n",
        "\n",
        "        bidirectionalはFalseにする(decoderでは使えない)\n",
        "        \"\"\"\n",
        "        super().__init__(vocab_size, embedding_dim, hidden_size, vocab_size, num_layers=num_layers, rnn_type='LSTM', bidirectional=False)\n",
        "        self.output_size = vocab_size\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "\n",
        "        \"\"\"\n",
        "        input :  前の層の予測 [batch_size,] インデックスになっている\n",
        "        hidden : 前の層の隠れ状態\n",
        "        cell : 前の層のcellの状態\n",
        "        順伝播を行う。1文字を処理をしてある文字がどの文字なのかを予測するlogitsの値が入っているoutputsを返す。\n",
        "        vocab_sizeクラスの分類といえる?\n",
        "        \"\"\"\n",
        "        input = input.unsqueeze(1) # [batch_size,] => [batch_size, 1]\n",
        "        embedded = self.embedding(input)  # embedded : [batch_size, 1, embedding_dim]\n",
        "        output_seq, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "\n",
        "        # output_seq : [batch_size, 1, hidden_size]\n",
        "        # hidden : [num_layers * 1, batch_size, hidden_size]\n",
        "        # cell : [num_layers * 1, batch_size, hidden_size]\n",
        "\n",
        "        prediction = self.fc(output_seq.squeeze(1)) # prediction : [batch_size, vocab_size]\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n"
      ],
      "metadata": {
        "id": "GA3DjBj2HbPO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "\n",
        "        \"\"\"\n",
        "        encoder : エンコーダ\n",
        "        decoder : デコーダー\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing=0.5):\n",
        "        \"\"\"\n",
        "        src : [batch_size, vocab_size]\n",
        "        tgt : [batch_size, ]\n",
        "        teacher_forcing : teacher forcingをする閾値を確率で設定する　大きい程teacher forcingしやすい\n",
        "        \"\"\"\n",
        "        batch_size = tgt.shape[0]\n",
        "        tgt_len = tgt.shape[1]\n",
        "        tgt_vocab_size = self.decoder.output_size\n",
        "\n",
        "        # encoderのforward\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "\n",
        "        # decoderのforward\n",
        "        outputs = torch.zeros((batch_size, tgt_len, tgt_vocab_size)).to(self.device)\n",
        "        input = tgt[:, 0] # <bos>\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            # output : [batch_size, vocab_size]\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = random.random() < teacher_forcing\n",
        "            top1 = output.argmax(1) # greedy sarch\n",
        "            input = tgt[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "gi_QEd_LMuO4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習ループ"
      ],
      "metadata": {
        "id": "WnuVFAgumNe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs,  model_save_path=None):\n",
        "\n",
        "    # ログ\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "\n",
        "    # deviceの設定\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_val_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        # training\n",
        "        for i, (src, tgt) in tqdm(enumerate(train_loader), desc='now training', total=len(train_loader), leave=False):\n",
        "            src = src.to(device)\n",
        "            # import pdb; pdb.set_trace()\n",
        "            tgt = tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(src, tgt) # [batch_size, tgt_len, tgt_vocab_en]\n",
        "            output_size = outputs.shape[-1]\n",
        "\n",
        "            outputs = outputs[:,1:].reshape(-1, output_size)# [batch_size * tgtq_len, tgt_vocab_en] outputs[:,0]は<bos>なので無視\n",
        "            tgt = tgt[:,1:].reshape(-1) # [batch_size, src_seq_len] -> [batch_size * src_seq_len]\n",
        "            loss = criterion(outputs, tgt)\n",
        "            loss.backward()\n",
        "            running_loss += loss.item()\n",
        "            optimizer.step()\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # validation\n",
        "        # 評価用\n",
        "\n",
        "        total_num = 0\n",
        "        total_correct = 0\n",
        "\n",
        "        for i, (src, tgt) in tqdm(enumerate(val_loader), desc='valdation', total=len(val_loader), leave=False):\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "\n",
        "                src = src.to(device)\n",
        "                tgt = tgt.to(device)\n",
        "                outputs = model(src, tgt, teacher_forcing=0) # [batch_size, seq_len, tgt_vocab_len], teacher_forcingなし\n",
        "\n",
        "                tgt = tgt[:,1:].reshape(-1) # [batch_size, src_seq_len] -> [batch_size * src_seq_len]\n",
        "\n",
        "                output_size = outputs.shape[-1]\n",
        "\n",
        "                outputs = outputs[:,1:].reshape(-1, output_size) # [batch_size * seq_len, tgt_vocab_en]\n",
        "\n",
        "                loss = criterion(outputs, tgt)\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "        val_losses.append(running_val_loss / len(val_loader))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"epoch={epoch}  train_losse={train_losses[-1]:.4f} val_loss={val_losses[-1]:.4f}\")\n",
        "\n",
        "\n",
        "        # モデル保存\n",
        "        if best_val_loss > val_losses[-1]:\n",
        "            best_val_loss = val_losses[-1]\n",
        "            torch.save(model.state_dict(), f'{model_save_path}/seq2seq_{epoch}' )\n",
        "            print(f'Model saved with validation loss: {best_val_loss:.4f}')\n",
        "\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "igy-QP2M4B9h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deviceの設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# vocab size\n",
        "tgt_vocab_size = len(vocab_transform[TGT_LANGUAGE])\n",
        "src_vocab_size = len(vocab_transform[SRC_LANGUAGE])\n",
        "\n",
        "embedding_dim = 300\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "\n",
        "# encoder,decoder\n",
        "enc = Encoder(src_vocab_size, embedding_dim, hidden_size=hidden_size, num_layers=num_layers)\n",
        "dec = Decoder(tgt_vocab_size ,embedding_dim, hidden_size, num_layers)\n",
        "\n",
        "# seq2seq\n",
        "model = Seq2Seq(enc, dec, device)\n",
        "\n",
        "# 損失関数とoptimizer\n",
        "learning_rate = 0.001\n",
        "opt = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab_transform[TGT_LANGUAGE]['<pad>'])"
      ],
      "metadata": {
        "id": "m12zQDZ94IcU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colabの準備\n",
        "from google.colab import drive\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)\n",
        "import sys\n",
        "now_path = drive_path + \"/MyDrive/深層学習/RNN\"\n",
        "sys.path.append(now_path)\n",
        "\n",
        "model_save_path = f'{now_path}/machine_translation_models'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Wwzlq49O-E",
        "outputId": "59099ab4-c538-46ca-dce0-90aa66334bfc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = train(model, train_loader, val_loader, opt, criterion, num_epochs, model_save_path = model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBm-MBbby47c",
        "outputId": "54b898bd-8dd0-4abb-90e2-747a97d87219"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0  train_losse=5.4504 val_loss=5.1271\n",
            "Model saved with validation loss: 5.1271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=1  train_losse=4.7562 val_loss=5.1479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=2  train_losse=4.5140 val_loss=5.0668\n",
            "Model saved with validation loss: 5.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=3  train_losse=4.3028 val_loss=4.9975\n",
            "Model saved with validation loss: 4.9975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=4  train_losse=4.1192 val_loss=5.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=5  train_losse=3.9588 val_loss=4.9471\n",
            "Model saved with validation loss: 4.9471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=6  train_losse=3.8082 val_loss=4.9037\n",
            "Model saved with validation loss: 4.9037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=7  train_losse=3.6644 val_loss=4.9100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=8  train_losse=3.5135 val_loss=4.9568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=9  train_losse=3.3865 val_loss=4.9345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=10  train_losse=3.2505 val_loss=4.9369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=11  train_losse=3.1026 val_loss=5.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=12  train_losse=2.9572 val_loss=5.1114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=13  train_losse=2.8143 val_loss=5.1646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=14  train_losse=2.6762 val_loss=5.2087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=15  train_losse=2.5094 val_loss=5.2792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=16  train_losse=2.3464 val_loss=5.3741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=17  train_losse=2.1700 val_loss=5.4845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=18  train_losse=2.0154 val_loss=5.6069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=19  train_losse=1.8239 val_loss=5.6380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "5Hh5jT1A-F_0",
        "outputId": "c02624df-5b53-4328-fa1b-90a4deb34377"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 推論コードを作る"
      ],
      "metadata": {
        "id": "khPvDurLKM6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(src_vocab_size, embedding_dim, hidden_size, num_layers)\n",
        "dec = Decoder(tgt_vocab_size, embedding_dim, hidden_size, num_layers)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "metadata": {
        "id": "siRcuCVJ6XX7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(f'{model_save_path}/seq2seq_7', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdcqoKKU7-Qt",
        "outputId": "e6ea2fa7-75b4-47ab-8629-af25acffc499"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, device, max_len=50):\n",
        "    max_len = max_len\n",
        "\n",
        "    sentence = sentence\n",
        "    # 1. tokenize\n",
        "    tokenized_sentence = token_transform[SRC_LANGUAGE](sentence)\n",
        "    # 2. 符号\n",
        "    numericalaized = [vocab_transform[SRC_LANGUAGE]['<bos>']]  \\\n",
        "                    + [vocab_transform[SRC_LANGUAGE][token] for token in tokenized_sentence] \\\n",
        "                    + [vocab_transform[SRC_LANGUAGE]['<eos>']]\n",
        "    # 3. Tnsor化\n",
        "    numericalaized = torch.LongTensor(numericalaized).unsqueeze(0).to(device)\n",
        "\n",
        "    # encoderのforward\n",
        "    hidden, cell = model.encoder(numericalaized)\n",
        "\n",
        "    # decoderへの最初の入力\n",
        "    input = torch.LongTensor([vocab_transform[TGT_LANGUAGE]['<bos>']]).to(device)\n",
        "\n",
        "    # Decoderのforwardで文章生成\n",
        "    translated_sentence = []\n",
        "    for _ in range(max_len):\n",
        "        output, hidden, cell = model.decoder(input, hidden, cell)\n",
        "        best_gess_index = output.argmax(1).item()\n",
        "        best_word = vocab_transform[TGT_LANGUAGE].lookup_token(best_gess_index)\n",
        "        translated_sentence.append(best_word)\n",
        "        if best_gess_index == vocab_transform[TGT_LANGUAGE]['<eos>']:\n",
        "            break\n",
        "        input = torch.LongTensor([best_gess_index]).to(device)\n",
        "    # ' '.join() はPythonの文字列メソッドで、リストやタプルに含まれる要素を一つの文字列として結合する際に使う\n",
        "    return ' '.join(translated_sentence)"
      ],
      "metadata": {
        "id": "x2xpNz5j8nAF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A boat with several men on it is being pulled to the shore by a large team of horses.\n",
        "sentence = \"Ein Boot mit mehreren Männern darauf wird von einem großen Pferdegespann ans Ufer gezogen.\"\n",
        "translated_sentence = translate_sentence(model, sentence, device, 50)\n",
        "translated_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3oJsXWbZ80R-",
        "outputId": "ffa97db9-48e8-4d9a-afd1-5953f433bdfc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A couple is a a a a while a a to a . <eos>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ' '.join([要素が文字列のリスト])"
      ],
      "metadata": {
        "id": "rD1nm4CxJSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['I', 'love', 'PyTorch']\n",
        "sentence = ' 　　　　'.join(words)\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6i3AwqMHSrW",
        "outputId": "2ea61c44-2452-4193-8d37-2dd2e691999b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I 　　　　love 　　　　PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beam_sarch"
      ],
      "metadata": {
        "id": "Uf8u4fTlJPbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence_beam_search(model, sentence, device, max_len=50, k=10, alpha=0.7):\n",
        "\n",
        "    # 1. tokenize\n",
        "    tokenized = token_transform[SRC_LANGUAGE](sentence)\n",
        "\n",
        "    # 2. 符号化,<bos>,<eos>を付ける\n",
        "    numericalized = [vocab_transform[SRC_LANGUAGE]['<bos>']] \\\n",
        "                + [vocab_transform[SRC_LANGUAGE][token] for token in tokenized] + \\\n",
        "                  [vocab_transform[SRC_LANGUAGE]['<eos>']]\n",
        "    # Tnsor化\n",
        "    numericalized = torch.LongTensor(numericalized).unsqueeze(0).to(device) #[1, tgt_len] -> [tgt_len]\n",
        "\n",
        "    # Encoderのforward\n",
        "    hidden, cell = model.encoder(numericalized)\n",
        "\n",
        "    # <bos> (最初のDecoderへの入力)]\n",
        "    input = torch.LongTensor([vocab_transform[SRC_LANGUAGE]['<bos>']]).to(device)\n",
        "\n",
        "\n",
        "    translated_sentence = []\n",
        "    beam = [(0, [vocab_transform[TGT_LANGUAGE]['<bos>']], hidden, cell)]\n",
        "    beam_log = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "\n",
        "        all_candidates = []\n",
        "        for score, word_list, hidden, cell in beam: # 最初は1回、次は10回\n",
        "            if word_list[-1] == vocab_transform[TGT_LANGUAGE]['<eos>']:\n",
        "                all_candidates.append((score, word_list, hidden, cell))\n",
        "            else:\n",
        "                output, hidden, cell = model.decoder(input, hidden, cell)\n",
        "                # output: [1, vocab_size]\n",
        "                probs = torch.log_softmax(output, dim=-1)\n",
        "                probs = probs.view(-1)\n",
        "\n",
        "            for i, prob in enumerate(probs): # tgt_vocab分\n",
        "                next_score = ((score * len(word_list)**alpha) + prob.item()) / ((len(word_list)+1)**alpha)\n",
        "                # (score, wordlist, hidden, cell)\n",
        "                all_candidates.append((next_score, word_list + [i], hidden, cell)) # [(0,[3,4,2,4...],[[[]]], [[[]]]), (0,[53,24,21,41...],[[[]]], [[[]]]), (0,[983,42,297,214...],[[[]]], [[[]]]) ]\n",
        "        all_candidates.sort(key=lambda x : x[0], reverse=True) # score基準に並べ替え\n",
        "        beam = all_candidates[:k]\n",
        "\n",
        "        # log用\n",
        "        beam_log.append(cand[0] for cand in all_candidates[:k])\n",
        "    return beam, beam_log\n"
      ],
      "metadata": {
        "id": "YFOoNEu0qbtX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A boat with several men on it is being pulled to the shore by a large team of horses.\n",
        "sentence = \"Ein Boot mit mehreren Männern darauf wird von einem großen Pferdegespann ans Ufer gezogen.\"\n",
        "beam, beam_log = translate_sentence_beam_search(model, sentence, device)"
      ],
      "metadata": {
        "id": "Cu_QTDps9tiy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in beam:\n",
        "    word_list = b[1]\n",
        "    translated_sentence = [vocab_transform[TGT_LANGUAGE].lookup_token(word_id) for word_id in word_list]\n",
        "    print(translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJXjvmRf-40C",
        "outputId": "b4d084d4-d17e-4fdd-c0b4-3cde2e2a7b3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'in', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'to', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'at', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'in', 'in', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'to', 'in', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'to', 'to', 'at', 'in', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'to', 'to', 'in', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'to', 'to', 'to', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'to', 'to', 'at', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "['<bos>', 'A', 'Asian', 'and', 'and', 'and', 'and', 'and', 'at', 'at', 'at', 'at', 'to', 'in', 'at', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n"
          ]
        }
      ]
    }
  ]
}