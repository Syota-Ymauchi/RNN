{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1547cd-df84-4d41-b4f0-3f176513c8f4",
   "metadata": {},
   "source": [
    "# RNNの復習はここに"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060093e-080e-44c0-a9a0-c5ed871f4130",
   "metadata": {},
   "source": [
    "### nerの復習\n",
    "\n",
    "###### データ読み込み\n",
    "###### label encoding\n",
    "###### 辞書作成　エンコード\n",
    "###### データ分割\n",
    "###### padding\n",
    "###### 学習準備\n",
    "###### モデルの定義\n",
    "###### 学習ループ\n",
    "###### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e39a23-923e-4462-a05a-a9d8870afe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465aa09-3373-4b2c-afe9-a1a93675122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルデータ\n",
    "with open('ner_dataset_labels.txt', 'rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "# sentenceデータ\n",
    "with open('ner_dataset_sentences.txt', 'rb') as fp:\n",
    "    sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ac483-b417-43de-bc51-d874cfba4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ee2638-d6c5-4e78-9eb2-d46e678717f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B-per', 'O', 'O', 'B-geo', 'I-geo', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'B-org', 'O'],\n",
       " ['O', 'B-geo', 'I-geo', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'B-geo', 'I-geo', 'I-geo', 'I-geo', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-org', 'I-org', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-org', 'I-org', 'O'],\n",
       " ['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O'],\n",
       " ['B-geo', 'I-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'B-geo', 'O', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'B-geo', 'O', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'B-org', 'O'],\n",
       " ['O', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'B-geo', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'B-org', 'O'],\n",
       " ['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B-per', 'I-per', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'B-geo', 'I-geo', 'I-geo', 'I-geo', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'B-geo', 'I-geo', 'I-geo', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'B-org', 'O'],\n",
       " ['O', 'B-geo', 'I-geo', 'O', 'O', 'B-geo', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'O'],\n",
       " ['O', 'O', 'O', 'B-geo', 'I-geo', 'O'],\n",
       " ['O', 'O', 'O', 'B-geo', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'O']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71022399-0ca9-49de-899b-830f29cbb7fe",
   "metadata": {},
   "source": [
    "### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79577827-b5ad-4632-bcd7-e5d29c0c6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18233e53-e8be-4c05-b0d8-8b66746ae1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず、全てのラベルを取得するために全データで1つのリストにする\n",
    "all_labels = [label for sublabel in labels for label in sublabel]\n",
    "\n",
    "# これに対してlabel encoderのfit\n",
    "label_encoder.fit(all_labels) # labelのidを作成する\n",
    "\n",
    "# labelsに対して適用する。padding用に+1することに注意\n",
    "encodered_labels = [label_encoder.transform(sublabel) + 1 for sublabel in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20bcb59f-cc93-4714-9af4-7c03236807bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7, 7, 7, 7, 7, 7, 7]),\n",
       " array([3, 7, 7, 1, 4, 7]),\n",
       " array([7, 7, 7, 7, 7]),\n",
       " array([7, 7, 7, 2, 7]),\n",
       " array([7, 1, 4, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 1, 4, 4, 4, 7]),\n",
       " array([7, 7, 7, 7, 2, 5, 7]),\n",
       " array([7, 7, 7, 7, 2, 5, 7]),\n",
       " array([1, 7, 7, 7, 7, 1, 7]),\n",
       " array([1, 4, 7, 7, 7, 7, 7, 7, 7, 7]),\n",
       " array([7, 1, 7, 7, 7, 7, 7, 7, 7, 7]),\n",
       " array([7, 1, 7, 7, 7, 1, 7]),\n",
       " array([7, 1, 7, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 2, 7]),\n",
       " array([7, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 7, 1, 7, 7, 7, 7]),\n",
       " array([7, 1, 7, 7, 7, 7, 7]),\n",
       " array([7, 7, 7, 2, 7]),\n",
       " array([3, 6, 7, 7, 7, 7, 7]),\n",
       " array([3, 7, 7, 7, 7, 7, 7, 7]),\n",
       " array([3, 6, 7, 7, 7, 7]),\n",
       " array([7, 1, 4, 4, 4, 7, 7, 1, 7]),\n",
       " array([7, 1, 4, 4, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 2, 7]),\n",
       " array([7, 1, 4, 7, 7, 1, 7]),\n",
       " array([7, 7, 7, 7, 7, 2, 5, 5, 7]),\n",
       " array([7, 7, 7, 1, 4, 7]),\n",
       " array([7, 7, 7, 1, 7, 7, 7]),\n",
       " array([7, 7, 7, 7, 2, 5, 5, 7])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodered_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b331b-6a95-4f49-a931-115cab252e1c",
   "metadata": {},
   "source": [
    "### 辞書作成 エンコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea0b4f7-43a9-4b86-806c-aca899084857",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2indx = {'<PAD>':0}\n",
    "encodered_sentences = []\n",
    "for sentence in sentences:\n",
    "    encodered_sentence = [word2indx.setdefault(word, len(word2indx)) for word in sentence.split() ]\n",
    "    encodered_sentences.append(encodered_sentence) # ここでようやく2次元に "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e82f87-e0d8-4c15-ba34-fcf32b2b7bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7],\n",
       " [8, 9, 10, 11, 12, 7],\n",
       " [13, 14, 15, 16, 7],\n",
       " [17, 18, 19, 20, 7],\n",
       " [1, 21, 22, 23, 10, 24, 7],\n",
       " [25, 23, 26, 27, 7],\n",
       " [13, 28, 5, 29, 30, 31, 32, 7],\n",
       " [17, 23, 33, 19, 34, 35, 7],\n",
       " [25, 18, 36, 5, 37, 38, 7],\n",
       " [39, 23, 5, 40, 31, 41, 7],\n",
       " [42, 43, 23, 5, 44, 45, 10, 5, 46, 7],\n",
       " [1, 47, 23, 5, 48, 49, 10, 5, 46, 7],\n",
       " [1, 50, 51, 52, 10, 53, 7],\n",
       " [1, 54, 55, 23, 10, 56, 7],\n",
       " [13, 57, 19, 58, 7],\n",
       " [17, 23, 26, 59, 7],\n",
       " [25, 23, 60, 61, 24, 36, 62, 63, 7],\n",
       " [1, 64, 23, 5, 65, 66, 7],\n",
       " [25, 67, 19, 68, 7],\n",
       " [69, 70, 23, 62, 71, 72, 7],\n",
       " [73, 23, 74, 36, 75, 76, 77, 7],\n",
       " [78, 79, 80, 62, 81, 7],\n",
       " [1, 82, 22, 31, 83, 23, 10, 84, 7],\n",
       " [1, 29, 85, 86, 23, 10, 59, 7],\n",
       " [17, 18, 19, 87, 7],\n",
       " [1, 88, 89, 23, 10, 90, 7],\n",
       " [17, 23, 33, 19, 5, 35, 31, 91, 7],\n",
       " [25, 9, 10, 92, 93, 7],\n",
       " [94, 51, 95, 96, 97, 98, 7],\n",
       " [25, 18, 36, 5, 99, 100, 101, 7]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1938031-40f7-4a4b-8600-ed9e6ce1a09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat': 6,\n",
       " '.': 7,\n",
       " 'John': 8,\n",
       " 'lives': 9,\n",
       " 'in': 10,\n",
       " 'New': 11,\n",
       " 'York': 12,\n",
       " 'I': 13,\n",
       " 'have': 14,\n",
       " 'two': 15,\n",
       " 'dogs': 16,\n",
       " 'She': 17,\n",
       " 'works': 18,\n",
       " 'at': 19,\n",
       " 'Google': 20,\n",
       " 'Eiffel': 21,\n",
       " 'Tower': 22,\n",
       " 'is': 23,\n",
       " 'Paris': 24,\n",
       " 'He': 25,\n",
       " 'from': 26,\n",
       " 'Spain': 27,\n",
       " 'visited': 28,\n",
       " 'Great': 29,\n",
       " 'Wall': 30,\n",
       " 'of': 31,\n",
       " 'China': 32,\n",
       " 'studying': 33,\n",
       " 'Oxford': 34,\n",
       " 'University': 35,\n",
       " 'for': 36,\n",
       " 'United': 37,\n",
       " 'Nations': 38,\n",
       " 'Berlin': 39,\n",
       " 'capital': 40,\n",
       " 'Germany': 41,\n",
       " 'Mount': 42,\n",
       " 'Everest': 43,\n",
       " 'highest': 44,\n",
       " 'peak': 45,\n",
       " 'world': 46,\n",
       " 'Nile': 47,\n",
       " 'longest': 48,\n",
       " 'river': 49,\n",
       " 'Pyramids': 50,\n",
       " 'are': 51,\n",
       " 'located': 52,\n",
       " 'Egypt': 53,\n",
       " 'Sahara': 54,\n",
       " 'desert': 55,\n",
       " 'Africa': 56,\n",
       " 'work': 57,\n",
       " 'Microsoft': 58,\n",
       " 'Australia': 59,\n",
       " 'going': 60,\n",
       " 'to': 61,\n",
       " 'a': 62,\n",
       " 'meeting': 63,\n",
       " 'Amazon': 64,\n",
       " 'largest': 65,\n",
       " 'rainforest': 66,\n",
       " 'studied': 67,\n",
       " 'Harvard': 68,\n",
       " 'Mona': 69,\n",
       " 'Lisa': 70,\n",
       " 'famous': 71,\n",
       " 'painting': 72,\n",
       " 'Shakespeare': 73,\n",
       " 'known': 74,\n",
       " 'Romeo': 75,\n",
       " 'and': 76,\n",
       " 'Juliet': 77,\n",
       " 'Albert': 78,\n",
       " 'Einstein': 79,\n",
       " 'was': 80,\n",
       " 'physicist': 81,\n",
       " 'Leaning': 82,\n",
       " 'Pisa': 83,\n",
       " 'Italy': 84,\n",
       " 'Barrier': 85,\n",
       " 'Reef': 86,\n",
       " 'Facebook': 87,\n",
       " 'Grand': 88,\n",
       " 'Canyon': 89,\n",
       " 'Arizona': 90,\n",
       " 'Tokyo': 91,\n",
       " 'Los': 92,\n",
       " 'Angeles': 93,\n",
       " 'They': 94,\n",
       " 'visiting': 95,\n",
       " 'London': 96,\n",
       " 'this': 97,\n",
       " 'summer': 98,\n",
       " 'World': 99,\n",
       " 'Health': 100,\n",
       " 'Organization': 101}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2indx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9c745-2a93-400c-9242-03d562826a4d",
   "metadata": {},
   "source": [
    "### 訓練データ、検証データに分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4b8c91-056e-4fdd-94c1-d0605b019fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1415acd7-ffa4-4c0a-8002-493851c629b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, train_sentences, val_sentences = train_test_split(encodered_sentences, encodered_labels, sentences, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196cefbc-0315-498f-a4a4-4ab7069ea55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6, 7]]\n",
      "[array([7, 7, 7, 7, 7, 7, 7])]\n",
      "['The cat sat on the mat .']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(train_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a014ec37-2b7c-418e-b319-3d20b3e00b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a055732-fb4d-4891-9f15-a519f81f8b02",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca2befb5-6e7b-4a1d-bcb3-b5a644085332",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequence([torch.tensor(x) for x in X_train], batch_first=True)\n",
    "X_val = pad_sequence([torch.tensor(x) for x in X_val], batch_first=True)\n",
    "y_train = pad_sequence([torch.tensor(y) for y in y_train], batch_first=True)\n",
    "y_val = pad_sequence([torch.tensor(y) for y in y_val], batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05757202-383c-4bad-a247-457c8f267c1e",
   "metadata": {},
   "source": [
    "### モデルの定義　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11331b4c-ada5-4a7f-bb4f-a223c3b270c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from mymodel import MyUGRNN, MyGRU, MyLSTM # 自作モジュール\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da3003c-f222-485e-9e54-de5ae036cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 自作のモデルが動くかテスト\n",
    "vocab_size = 30 # データセット内での最大文字数\n",
    "embeling_dim = 10 # 各単語のベクトルの次元\n",
    "batch_size = 8\n",
    "# num_classes = 3\n",
    "hidden_size = 9\n",
    "input_tensor = torch.randn((batch_size, vocab_size, embeling_dim))\n",
    "test_model = MyLSTM(embeling_dim, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d46463-c520-4919-a501-ab605a605a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq, (h_n, c_n) = test_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cbeed0f-59d0-4aa2-b201-e565dedd27ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 30, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d037775-aed5-494c-b85e-777871cbdd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4503ea-a677-4604-9eea-9c2f4703ef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea60c1-9e20-4a9d-b305-0d3b6645960e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
